{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver  \n",
    "import time \n",
    "import re\n",
    "from lxml import etree\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4 as bs\n",
    "from selenium.common.exceptions import NoSuchElementException \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "import pandas as pd\n",
    "\n",
    "URLs_brand = []\n",
    "#browser = webdriver.Firefox()#Chrome('./chromedriver.exe') \n",
    "whole = ['2-a','3-b','4-c','5-d','6-e','7-f','8-g','9-h','10-i','11-j','12-k','13-l','14-m','15-n','16-o','17-p',\n",
    "        '18-q','19-r','20-s','21-t','22-u','23-v','24-w','25-x','26-y','27-z'] \n",
    "\n",
    "# For every page in the interval\n",
    "for wh in whole:\n",
    "    PATIENCE_TIME = 60 \n",
    "    driver = webdriver.Chrome() \n",
    "    driver.get('https://www.nosetime.com/pinpai/'+str(wh)+'.html') \n",
    "    driver.encoding = 'utf-8'\n",
    "    driver.maximize_window()\n",
    "\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    url_containers = soup.find_all('div', class_='odorlist')\n",
    "\n",
    "    for container in url_containers:\n",
    "        #find all the date of the news\n",
    "        try: \n",
    "            for url_b in container.find_all('a'): \n",
    "                url_brand = url_b.get('href')\n",
    "                URLs_brand.append(url_brand)\n",
    "        except: \n",
    "            url_brand = \"no_url\"\n",
    "            URLs_brand.append(url_brand)\n",
    "    driver.close()\n",
    "driver.quit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/pinpai/10091761-oulong-atelier-cologne.html', '/pinpai/10091761-oulong-atelier-cologne.html', '/pinpai/10056110-annikeguteer-annick-goutal.html', '/pinpai/10056110-annikeguteer-annick-goutal.html', '/pinpai/10051198-paermazhishui-acqua-di-parma.html', '/pinpai/10051198-paermazhishui-acqua-di-parma.html', '/pinpai/10020871-aimu-amouage.html', '/pinpai/10020871-aimu-amouage.html', '/pinpai/10035498-annasu-anna-sui.html', '/pinpai/10035498-annasu-anna-sui.html']\n"
     ]
    }
   ],
   "source": [
    "print(URLs_brand[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4080"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URLs_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2040"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cleaned_URls_brand = set(URLs_brand)\n",
    "len(Cleaned_URls_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2040 entries, 0 to 2039\n",
      "Data columns (total 1 columns):\n",
      "Brand_id    2040 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 16.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#get the pure id of brand\n",
    "Brand_id = []\n",
    "for i in Cleaned_URls_brand:\n",
    "    brand_id = re.sub(r'[^0-9]','',i)\n",
    "    Brand_id.append(brand_id)\n",
    "datapage1 = {\n",
    "    'Brand_id': Brand_id,\n",
    "}\n",
    "brandid = pd.DataFrame.from_dict(datapage1, orient ='index').transpose()\n",
    "print(brandid.info())\n",
    "brandid.to_csv('Brand_id.csv',index = False, encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10014016', '10078016', '10054734', '10093177', '10075765', '10038916', '10015637', '10068357', '10063657', '10010461']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "Brand_id=[]\n",
    "with open('Brand_id.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in f:\n",
    "        Brand_id = [row[0] for row in reader]\n",
    "        print(Brand_id[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这是有多少个品牌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2040"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Brand_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2040"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(Brand_id)\n",
    "len(Brand_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获得page >1的所有urls\n",
    "URLs = []\n",
    "#browser = webdriver.Firefox()#Chrome('./chromedriver.exe') \n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from time import sleep\n",
    "# For every page in the interval\n",
    "for bid in Brand_id:\n",
    "    PATIENCE_TIME = 60 \n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get('https://www.nosetime.com/brand.php?id='+str(bid))\n",
    "    driver.encoding = 'utf-8'\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    all_url_container = soup.find_all('div', class_='next_news')\n",
    "    \n",
    "    for container in all_url_container:\n",
    "        try: \n",
    "            for url in container.find_all('a'): \n",
    "                URLs.append(\"https://www.nosetime.com/brand.php?id=\"+str(bid)+\"page=\"+url.text)\n",
    "                \n",
    "        except: \n",
    "            urls = \"no_allurls\"\n",
    "            URLs.append(allurls)\n",
    "        driver.close()\n",
    "        time.sleep(1)\n",
    "driver.quit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3424"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(URLs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2226"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#删除URL中不需要的，比如含有下一页和尾页的URL\n",
    "p_urls = []\n",
    "error = []\n",
    "for i in AllURLs:\n",
    "    if not \"下一页\" in i:\n",
    "        if not \"尾页\" in i:\n",
    "            p_urls.append(i)\n",
    "    else: error.append(i)\n",
    "len(p_urls)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.nosetime.com/brand.php?id=10014016page=下一页', 'https://www.nosetime.com/brand.php?id=10054734page=下一页', 'https://www.nosetime.com/brand.php?id=10010461page=下一页', 'https://www.nosetime.com/brand.php?id=10061680page=下一页', 'https://www.nosetime.com/brand.php?id=10029483page=下一页', 'https://www.nosetime.com/brand.php?id=10098532page=下一页', 'https://www.nosetime.com/brand.php?id=10035498page=下一页', 'https://www.nosetime.com/brand.php?id=10030919page=下一页', 'https://www.nosetime.com/brand.php?id=10075007page=下一页', 'https://www.nosetime.com/brand.php?id=10077602page=下一页']\n"
     ]
    }
   ],
   "source": [
    "#检查这些不需要的URLs\n",
    "print(error[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2226 entries, 0 to 2225\n",
      "Data columns (total 1 columns):\n",
      "p_urls    2226 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 17.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#将香水的page>1的url存入一个csv\n",
    "datapage2 = {\n",
    "    'p_urls': p_urls,\n",
    "}\n",
    "p_urls = pd.DataFrame.from_dict(datapage2, orient ='index').transpose()\n",
    "print(p_urls.info())\n",
    "p_urls.to_csv('part_urls.csv',index = False, encoding = 'utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入该csv\n",
    "import csv\n",
    "purls=[]\n",
    "with open('part_urls.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for line in f:\n",
    "        purls = [row[0] for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "part_id = []\n",
    "for i in purls:\n",
    "    newi = re.split('\\d+$',i) #移除url最后的数字\n",
    "    newi1 = re.sub(r'[^0-9]','',newi[0])\n",
    "    part_id.append(newi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_id = set(part_id)\n",
    "len(part_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1441"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#这里是香水page=1的所有url。\n",
    "another_url = []\n",
    "for i in Brand_id: #all_brand_id\n",
    "    if i not in part_id: #find the singel page brand id\n",
    "        another_url.append(\"https://www.nosetime.com/brand.php?id=\"+str(i)) #append the single page url\n",
    "len(another_url) #the number is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这是有多少个URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3667"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_urls = purls + another_url\n",
    "len(whole_urls)#2226+1441=3667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3667 entries, 0 to 3666\n",
      "Data columns (total 1 columns):\n",
      "whole_urls     3667 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 28.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#write all the urls into the csv files\n",
    "datapage3 = {\n",
    "    'whole_urls ': whole_urls,\n",
    "}\n",
    "whole_urls = pd.DataFrame.from_dict(datapage3, orient ='index').transpose()\n",
    "print(whole_urls.info())\n",
    "whole_urls.to_csv('whole_urls.csv',index = False, encoding = 'utf_8_sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
